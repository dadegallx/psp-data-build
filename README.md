# Data Build Tool (dbt) Project

This repository contains a dbt (data build tool) project for creating a semantic data layer from your PostgreSQL database. dbt is a transformation framework that enables data teams to transform raw data in their warehouse by simply writing select statements, turning them into a reliable and documented data pipeline.

## What is dbt?

dbt (data build tool) is an open-source command-line tool that enables data analysts and engineers to transform data in their warehouse by writing simple SQL select statements. dbt handles the complexity of:

- **Dependencies**: Automatically builds models in the correct order
- **Testing**: Validates data quality with built-in and custom tests
- **Documentation**: Generates comprehensive documentation from your code
- **Version Control**: Integrates with Git for collaborative development
- **Incremental Processing**: Processes only new or changed data when appropriate

Think of dbt as "software engineering best practices for data transformations."

## Project Structure

```
â”œâ”€â”€ data_model/                   # Data warehouse design documentation
â”‚   â”œâ”€â”€ SCHEMA_REFERENCE.md      # Star schema specifications
â”‚   â””â”€â”€ BUSINESS_QUESTIONS_DOCS.md  # Business questions and metrics
â”œâ”€â”€ dbt/                          # dbt project directory
â”‚   â”œâ”€â”€ models/                   # SQL transformation models
â”‚   â”‚   â”œâ”€â”€ _sources.yml         # Source table definitions
â”‚   â”‚   â”œâ”€â”€ staging/             # Raw data cleaning models
â”‚   â”‚   â”œâ”€â”€ intermediate/        # Business logic transformations
â”‚   â”‚   â”œâ”€â”€ marts/               # Business-ready analytical models
â”‚   â”‚   â””â”€â”€ semantic/            # MetricFlow semantic layer (future)
â”‚   â”œâ”€â”€ tests/                   # Custom data quality tests
â”‚   â”œâ”€â”€ dbt_project.yml         # Project configuration
â”‚   â””â”€â”€ profiles.yml             # Database connection settings
â”œâ”€â”€ claude-skills/               # Claude Code AI skills for development
â”œâ”€â”€ .claude/
â”‚   â””â”€â”€ CLAUDE.md               # Claude Code project guidance
â”œâ”€â”€ .env                        # Environment variables (not in git)
â”œâ”€â”€ .env.template               # Template for required variables
â””â”€â”€ pyproject.toml              # Python dependencies
```

## Claude Skills for AI-Assisted Development

This project includes custom Claude Code skills to accelerate dbt development:

### Available Skills

**ðŸ“¦ dbt-model-builder**: Core dbt workflows for creating models, sources, tests, and documentation
**ðŸ“Š metricflow-builder**: Semantic layer development with dbt's MetricFlow

### Quick Start

If you're using Claude Code, install the skills to get AI-powered assistance:

```bash
# Skills are located in the claude-skills/ directory
# See claude-skills/README.md for installation instructions
```

The skills provide:
- Step-by-step guidance for dbt development tasks
- Templates for staging, fact, and dimension models
- Best practices for testing and documentation
- MetricFlow semantic model and metrics patterns

**â†’ See [claude-skills/README.md](claude-skills/README.md) for full installation and usage guide**

## Local Development Setup

### Prerequisites

- **Python 3.8+**
- **uv package manager** (preferred over pip)
- **PostgreSQL database access**
- **Git** (for version control)

### Installation Steps

1. **Clone and navigate to the project:**
   ```bash
   git clone <repository-url>
   cd <project-directory>
   ```

2. **Install Python dependencies:**
   ```bash
   uv sync
   ```

3. **Activate the virtual environment:**
   ```bash
   source .venv/bin/activate
   ```

4. **Configure database connection:**

   Copy the template and fill in your database credentials:
   ```bash
   cp .env.template .env
   ```

   Edit `.env` with your PostgreSQL connection details:
   ```bash
   export DBT_HOST="your-postgres-host"
   export DBT_USER="your-username"
   export DBT_PASSWORD="your-password"
   export DBT_PORT="5432"
   export DBT_DBNAME="your-database-name"
   export DBT_SCHEMA="dbt_dev"  # Your development schema
   ```

5. **Test the database connection:**
   ```bash
   cd dbt
   source ../.env && dbt debug
   ```

### Essential dbt Commands

**Development workflow:**
```bash
# Check for syntax errors without running
dbt compile

# Run all models
dbt run

# Run specific model
dbt run --select model_name

# Run models by tag
dbt run --select tag:staging

# Test data quality
dbt test

# Generate and serve documentation
dbt docs generate && dbt docs serve
```

**Understanding the models:**

Your DBT project organizes SQL transformations as models, typically in a structure like:

```
models/
â”œâ”€â”€ staging/      # Clean and standardize raw data
â”œâ”€â”€ intermediate/ # Business logic transformations  
â””â”€â”€ marts/        # Final analysis-ready tables
```

## Production Deployment

dbt is a batch transformation tool that runs on-demand. For production, dbt runs can be scheduled using orchestration tools like AWS EventBridge, Apache Airflow, or dbt Cloud. The frequency depends on your data freshness requirements.

## Data Quality & Testing

This project includes comprehensive data quality tests:

- **Schema tests**: Not null, unique, relationships, accepted values
- **Custom tests**: Business logic validation
- **Source freshness**: Monitor data pipeline health

Run tests regularly:
```bash
dbt test                    # Run all tests
dbt test --select model_name  # Test specific model
```

## Documentation

Generate and view project documentation:
```bash
dbt docs generate
dbt docs serve  # Opens at http://localhost:8080
```

The documentation includes:
- Model descriptions and column definitions
- Data lineage graphs showing model dependencies
- Source data profiling and statistics
- Test results and data quality metrics

## Next Steps

After successful setup:

1. **Review the data model** - See `data_model/schema_docs/SCHEMA_REFERENCE.md` for schema design
2. **Explore business requirements** - Review `data_model/schema_docs/BUSINESS_QUESTIONS_DOCS.md`
3. **Install Claude skills** (optional) - See `claude-skills/README.md` for AI assistance
4. **View documentation** - Run `dbt docs serve` to explore the project
5. **Run transformations** - Execute `dbt run` to build models
6. **Connect your BI tool** to the transformed data tables